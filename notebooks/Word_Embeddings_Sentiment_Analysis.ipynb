{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Word Embeddings e Sentiment Analysis (PyTorch puro)\n","\n","Este notebook demonstra como representar palavras por vetores densos (*word embeddings*) e usá-los em uma tarefa de classificação de sentimentos usando apenas PyTorch.\n","\n","Etapas:\n","1. Preparar um pequeno corpus rotulado (positivo/negativo)\n","2. Tokenizar e mapear palavras para índices\n","3. Criar embeddings aprendíveis\n","4. Treinar um classificador simples\n","5. Avaliar e testar previsões"]},{"cell_type":"code","execution_count":1,"id":"f98d4e5a","metadata":{},"outputs":[],"source":["# pip install torch torchvision torchaudio"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","A module that was compiled using NumPy 1.x cannot be run in\n","NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n","versions of NumPy, modules must be compiled with NumPy 2.0.\n","Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n","\n","If you are a user of the module, the easiest solution will be to\n","downgrade to 'numpy<2' or try to upgrade the affected module.\n","We expect that some modules will need time to support NumPy 2.\n","\n","Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n","    app.launch_new_instance()\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n","    app.start()\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n","    self.io_loop.start()\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n","    self._run_once()\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n","    handle._run()\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n","    await self.process_one()\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n","    await dispatch(*args)\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n","    await result\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n","    await super().execute_request(stream, ident, parent)\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n","    reply_content = await reply_content\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n","    res = shell.run_cell(\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n","    result = self._run_cell(\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n","    result = runner(coro)\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n","    if await self.run_code(code, result, async_=asy):\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/var/folders/91/qbr5td611v3f7_c_dz8zmxmm0000gn/T/ipykernel_55512/2992936628.py\", line 1, in <module>\n","    import torch\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n","    from .functional import *  # noqa: F403\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n","    import torch.nn.functional as F\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n","    from .modules import *  # noqa: F403\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n","    from .transformer import TransformerEncoder, TransformerDecoder, \\\n","  File \"/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n","    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n","/Users/ebezerra/miniconda3/envs/gcc1626/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n","  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Conjunto de dados simples"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["corpus = [\n","    (\"o filme foi ótimo e emocionante\", 1),\n","    (\"adorei o enredo e os personagens\", 1),\n","    (\"a atuação foi excelente\", 1),\n","    (\"o filme é terrível e cansativo\", 0),\n","    (\"péssimo roteiro e trilha sonora ruim\", 0),\n","    (\"não gostei do final\", 0),\n","]"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Tokenização e vocabulário"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulário: {'<pad>': 0, '<unk>': 1, 'o': 2, 'filme': 3, 'foi': 4, 'ótimo': 5, 'e': 6, 'emocionante': 7, 'adorei': 8, 'enredo': 9, 'os': 10, 'personagens': 11, 'a': 12, 'atuação': 13, 'excelente': 14, 'é': 15, 'terrível': 16, 'cansativo': 17, 'péssimo': 18, 'roteiro': 19, 'trilha': 20, 'sonora': 21, 'ruim': 22, 'não': 23, 'gostei': 24, 'do': 25, 'final': 26}\n","[([2, 3, 4, 5, 6, 7, 0, 0], 1), ([8, 2, 9, 6, 10, 11, 0, 0], 1)]\n"]}],"source":["def tokenize(text):\n","    return text.lower().split()\n","\n","vocab = {\"<pad>\": 0, \"<unk>\": 1}\n","for sentence, _ in corpus:\n","    for tok in tokenize(sentence):\n","        if tok not in vocab:\n","            vocab[tok] = len(vocab)\n","\n","vocab_size = len(vocab)\n","print(\"Vocabulário:\", vocab)\n","\n","def encode(sentence, max_len=8):\n","    tokens = tokenize(sentence)\n","    ids = [vocab.get(t, 1) for t in tokens]\n","    if len(ids) < max_len:\n","        ids += [0] * (max_len - len(ids))\n","    else:\n","        ids = ids[:max_len]\n","    return ids\n","\n","max_len = 8\n","encoded = [(encode(s, max_len), y) for s, y in corpus]\n","print(encoded[:2])"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Dataset e DataLoader"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class SentimentDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","    def __len__(self):\n","        return len(self.data)\n","    def __getitem__(self, idx):\n","        x, y = self.data[idx]\n","        return torch.tensor(x), torch.tensor(y, dtype=torch.float32)\n","\n","dataset = SentimentDataset(encoded)\n","loader = DataLoader(dataset, batch_size=2, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Modelo com embeddings aprendíveis"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class EmbeddingClassifier(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_size, emb_dim)\n","        self.fc1 = nn.Linear(emb_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, 1)\n","        self.act = nn.ReLU()\n","        self.out = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        emb = self.emb(x)\n","        mean_emb = emb.mean(dim=1)\n","        h = self.act(self.fc1(mean_emb))\n","        y = self.out(self.fc2(h))\n","        return y.squeeze()\n","\n","model = EmbeddingClassifier(vocab_size, emb_dim=16, hidden_dim=8)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Treinamento"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Época 05 | Loss: 0.6770\n","Época 10 | Loss: 0.6087\n","Época 15 | Loss: 0.4520\n","Época 20 | Loss: 0.2313\n","Época 25 | Loss: 0.0836\n"]}],"source":["for epoch in range(25):\n","    total_loss = 0\n","    for xb, yb in loader:\n","        optimizer.zero_grad()\n","        preds = model(xb) # forward pass\n","        loss = criterion(preds, yb) # loss\n","        loss.backward() # backpropagation\n","        optimizer.step() # parameter update\n","        total_loss += loss.item()\n","    if (epoch+1) % 5 == 0:\n","        print(f\"Época {epoch+1:02d} | Loss: {total_loss/len(loader):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Teste com novas frases"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["amei o filme e a trilha sonora → negativo (0.11)\n","o roteiro é fraco e entediante → negativo (0.14)\n","personagens excelentes e cativantes → negativo (0.43)\n","não recomendo o filme → negativo (0.34)\n"]}],"source":["def predict(sentence):\n","    x = torch.tensor(encode(sentence, max_len)).unsqueeze(0)\n","    with torch.no_grad():\n","        p = model(x).item()\n","    label = \"positivo\" if p >= 0.5 else \"negativo\"\n","    return f\"{sentence} → {label} ({p:.2f})\"\n","\n","for s in [\n","    \"amei o filme e a trilha sonora\",\n","    \"o roteiro é fraco e entediante\",\n","    \"personagens excelentes e cativantes\",\n","    \"não recomendo o filme\",\n","]:\n","    print(predict(s))"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Visualizando embeddings"]},{"cell_type":"code","execution_count":10,"id":"59aae5b4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dimensão: torch.Size([27, 16])\n","Mais próximos de 'filme': [('é', 0.4726399779319763), ('sonora', 0.38141706585884094), ('e', 0.2239847481250763), ('roteiro', 0.12832169234752655), ('trilha', 0.11593659222126007)]\n"]}],"source":["emb_weights = model.emb.weight.detach()\n","print(\"Dimensão:\", emb_weights.shape)\n","\n","def closest(word, topn=5):\n","    if word not in vocab: \n","        return []\n","    idx = vocab[word]\n","    wv = emb_weights[idx]\n","    # similaridade de cosseno em PyTorch\n","    sims = torch.nn.functional.cosine_similarity(emb_weights, wv.unsqueeze(0))\n","    best = torch.argsort(sims, descending=True)[1:topn+1]\n","    inv_vocab = {i: w for w, i in vocab.items()}\n","    return [(inv_vocab[int(i)], float(sims[i])) for i in best]\n","\n","print(\"Mais próximos de 'filme':\", closest(\"filme\"))\n"]}],"metadata":{"kernelspec":{"display_name":"gcc1626","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":5}
