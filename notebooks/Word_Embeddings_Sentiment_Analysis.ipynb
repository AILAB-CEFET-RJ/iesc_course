{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Word Embeddings e Sentiment Analysis (PyTorch puro)\n","\n","Este notebook demonstra como representar palavras por vetores densos (*word embeddings*) e usá-los em uma tarefa de classificação de sentimentos usando apenas PyTorch.\n","\n","Etapas:\n","1. Preparar um pequeno corpus rotulado (positivo/negativo)\n","2. Tokenizar e mapear palavras para índices\n","3. Criar embeddings aprendíveis\n","4. Treinar um classificador simples\n","5. Avaliar e testar previsões"]},{"cell_type":"code","execution_count":152,"id":"f98d4e5a","metadata":{},"outputs":[],"source":["# pip install torch torchvision torchaudio"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Conjunto de dados simples"]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[],"source":["corpus = [\n","    (\"a película foi ótima e emocionante\", 1),\n","    (\"o filme foi ótimo e emocionante\", 1),\n","    (\"adorei o enredo e os personagens\", 1),\n","    (\"a atuação foi excelente\", 1),\n","    (\"o filme é terrível e cansativo\", 0),\n","    (\"péssimo roteiro e trilha sonora ruim\", 0),\n","    (\"não gostei do final\", 0),\n","]"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Tokenização e vocabulário"]},{"cell_type":"code","execution_count":155,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulário: {'<pad>': 0, '<unk>': 1, 'a': 2, 'película': 3, 'foi': 4, 'ótima': 5, 'e': 6, 'emocionante': 7, 'o': 8, 'filme': 9, 'ótimo': 10, 'adorei': 11, 'enredo': 12, 'os': 13, 'personagens': 14, 'atuação': 15, 'excelente': 16, 'é': 17, 'terrível': 18, 'cansativo': 19, 'péssimo': 20, 'roteiro': 21, 'trilha': 22, 'sonora': 23, 'ruim': 24, 'não': 25, 'gostei': 26, 'do': 27, 'final': 28}\n","[([2, 3, 4, 5, 6, 7, 0, 0], 1), ([8, 9, 4, 10, 6, 7, 0, 0], 1)]\n"]}],"source":["def tokenize(text):\n","    return text.lower().split()\n","\n","vocab = {\"<pad>\": 0, \"<unk>\": 1}\n","for sentence, _ in corpus:\n","    for tok in tokenize(sentence):\n","        if tok not in vocab:\n","            vocab[tok] = len(vocab)\n","\n","vocab_size = len(vocab)\n","print(\"Vocabulário:\", vocab)\n","\n","def encode(sentence, max_len=8):\n","    tokens = tokenize(sentence)\n","    ids = [vocab.get(t, 1) for t in tokens]\n","    if len(ids) < max_len:\n","        ids += [0] * (max_len - len(ids))\n","    else:\n","        ids = ids[:max_len]\n","    return ids\n","\n","max_len = 8\n","encoded = [(encode(s, max_len), y) for s, y in corpus]\n","print(encoded[:2])"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Dataset e DataLoader"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[],"source":["class SentimentDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","    def __len__(self):\n","        return len(self.data)\n","    def __getitem__(self, idx):\n","        x, y = self.data[idx]\n","        return torch.tensor(x), torch.tensor(y, dtype=torch.float32)\n","\n","dataset = SentimentDataset(encoded)\n","loader = DataLoader(dataset, batch_size=2, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Modelo com embeddings aprendíveis"]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[],"source":["class EmbeddingClassifier(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_size, emb_dim)\n","        self.fc1 = nn.Linear(emb_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, 1)\n","        self.act = nn.ReLU()\n","        self.out = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        emb = self.emb(x)\n","        mean_emb = emb.mean(dim=1)\n","        h = self.act(self.fc1(mean_emb))\n","        y = self.out(self.fc2(h))\n","        #return y.squeeze()\n","        return y.view(-1)\n","\n","\n","model = EmbeddingClassifier(vocab_size, emb_dim=16, hidden_dim=8)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Treinamento"]},{"cell_type":"code","execution_count":158,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","Época 05 | Loss: 0.5927\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","Época 10 | Loss: 0.3716\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","Época 15 | Loss: 0.1140\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","Época 20 | Loss: 0.0230\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([2]) torch.Size([2])\n","torch.Size([1]) torch.Size([1])\n","Época 25 | Loss: 0.0115\n"]}],"source":["for epoch in range(25):\n","    total_loss = 0\n","    for xb, yb in loader:\n","        optimizer.zero_grad()\n","        preds = model(xb) # forward pass\n","        print(preds.shape, yb.shape)\n","        loss = criterion(preds, yb) # loss\n","        loss.backward() # backpropagation\n","        optimizer.step() # parameter update\n","        total_loss += loss.item()\n","    if (epoch+1) % 5 == 0:\n","        print(f\"Época {epoch+1:02d} | Loss: {total_loss/len(loader):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Teste com novas frases"]},{"cell_type":"code","execution_count":159,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["amei o filme e a trilha sonora → negativo (0.05)\n","o roteiro é fraco e entediante → negativo (0.25)\n","personagens excelentes e cativantes → positivo (0.97)\n","não recomendo o filme → negativo (0.22)\n"]}],"source":["def predict(sentence):\n","    x = torch.tensor(encode(sentence, max_len)).unsqueeze(0)\n","    with torch.no_grad():\n","        p = model(x).item()\n","    label = \"positivo\" if p >= 0.5 else \"negativo\"\n","    return f\"{sentence} → {label} ({p:.2f})\"\n","\n","for s in [\n","    \"amei o filme e a trilha sonora\",\n","    \"o roteiro é fraco e entediante\",\n","    \"personagens excelentes e cativantes\",\n","    \"não recomendo o filme\",\n","]:\n","    print(predict(s))"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Visualizando embeddings"]},{"cell_type":"code","execution_count":160,"id":"59aae5b4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dimensão: torch.Size([29, 16])\n","Mais próximos de 'filme': [('<pad>', 0.3396492600440979), ('trilha', 0.3035092055797577), ('final', 0.2873351275920868), ('do', 0.21413035690784454), ('terrível', 0.1970217525959015)]\n"]}],"source":["emb_weights = model.emb.weight.detach()\n","print(\"Dimensão:\", emb_weights.shape)\n","\n","def closest(word, topn=5):\n","    if word not in vocab: \n","        return []\n","    idx = vocab[word]\n","    wv = emb_weights[idx]\n","    # similaridade de cosseno em PyTorch\n","    sims = torch.nn.functional.cosine_similarity(emb_weights, wv.unsqueeze(0))\n","    best = torch.argsort(sims, descending=True)[1:topn+1]\n","    inv_vocab = {i: w for w, i in vocab.items()}\n","    return [(inv_vocab[int(i)], float(sims[i])) for i in best]\n","\n","print(\"Mais próximos de 'filme':\", closest(\"filme\"))\n"]}],"metadata":{"kernelspec":{"display_name":"cic1205","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":5}
